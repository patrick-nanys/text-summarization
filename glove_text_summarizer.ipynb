{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove_text_summarizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrick-nanys/text-summarization/blob/main/glove_text_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLvBco2J-xK"
      },
      "source": [
        "## Deep learning homework - Milestone 2\n",
        "#####Topic: NLP - text summarization\n",
        "#####Authors: Patrick Nanys, Mate Jakab (Goal Diggers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGZDgfz_a6HG"
      },
      "source": [
        "###1. Data load from xlsx \n",
        "\n",
        "> Source: https://www.kaggle.com/shashichander009/inshorts-news-data\n",
        "> Source2.0: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xvnnp7tDz5X"
      },
      "source": [
        "!\\cp drive/MyDrive/Colab\\ Notebooks/Deep\\ learning/reviews.xlsx reviews.xlsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAEriAFohCba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913adc0b-f9e8-4b99-9b10-9808a25e5867"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#xls = pd.read_excel(\"Inshorts Cleaned Data.xlsx\")\n",
        "xls = pd.read_excel(\"reviews.xlsx\")\n",
        "xls['headline_type'] = xls['Headline'].apply(type)\n",
        "xls.drop(xls[xls.headline_type != str].index, inplace=True)\n",
        "# Load articles, stories\n",
        "input_raw = xls['Short']\n",
        "# Load headlines for articles and stories\n",
        "output_raw = xls['Headline']\n",
        "\n",
        "# Show example\n",
        "print(input_raw.head(), output_raw.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    I have bought several of the Vitality canned d...\n",
            "1    Product arrived labeled as Jumbo Salted Peanut...\n",
            "2    This is a confection that has been around a fe...\n",
            "3    If you are looking for the secret ingredient i...\n",
            "4    Great taffy at a great price.  There was a wid...\n",
            "Name: Short, dtype: object 0    Good Quality Dog Food\n",
            "1        Not as Advertised\n",
            "2    \"Delight\" says it all\n",
            "3           Cough Medicine\n",
            "4              Great taffy\n",
            "Name: Headline, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5NArR5oguZC"
      },
      "source": [
        "##### Obtaining length data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVFDLC_pg0FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20c226f-cea6-471d-9d6e-6aa1415874f1"
      },
      "source": [
        "input_lengths = pd.Series([len(x) for x in input_raw])\n",
        "output_lengths = pd.Series([len(str(x)) for x in output_raw])\n",
        "print('Inputs:\\n', input_lengths.describe())\n",
        "print('Outputs:\\n', output_lengths.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            " count    568427.000000\n",
            "mean        436.239369\n",
            "std         445.354882\n",
            "min          12.000000\n",
            "25%         179.000000\n",
            "50%         302.000000\n",
            "75%         527.000000\n",
            "max       21409.000000\n",
            "dtype: float64\n",
            "Outputs:\n",
            " count    568427.000000\n",
            "mean         23.446990\n",
            "std          14.028431\n",
            "min           1.000000\n",
            "25%          13.000000\n",
            "50%          20.000000\n",
            "75%          30.000000\n",
            "max         128.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvKS-MbphCPK"
      },
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 525\n",
        "decoder_maxlen = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL15_ImQtNup"
      },
      "source": [
        "def dataset_split(X, Y, valid_split, test_split):\n",
        "  v_start = int(len(X)*(1-valid_split-test_split))\n",
        "  t_start = int(len(X)*(1-test_split))\n",
        "  X_train, Y_train = X[:v_start], Y[:v_start]\n",
        "  X_valid, Y_valid = X[v_start:t_start], Y[v_start:t_start]\n",
        "  X_test , Y_test  = X[t_start:], Y[t_start:]\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpJ1ilXkPpqW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oX677bmTujP"
      },
      "source": [
        "input_raw = input_raw[:50000]\n",
        "output_raw = output_raw[:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb8R6IFDXcAV"
      },
      "source": [
        "all_raw = input_raw.append(output_raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEaZZR6NeSjp"
      },
      "source": [
        "# run this if you want to make sure to include the start and end tokens\n",
        "bunch_of_start_token_text = ' '.join([start_token] * 1000)\n",
        "bunch_of_end_token_text = ' '.join([end_token] * 1000)\n",
        "\n",
        "all_raw.append(pd.Series(bunch_of_start_token_text)).append(pd.Series(bunch_of_end_token_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M15_G76jYPT"
      },
      "source": [
        "start_token = 'sostr'\n",
        "end_token = 'eostr'\n",
        "def apply_start_end(text):\n",
        "  return start_token + ' ' + text + ' ' + end_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2eodRQIjgOq"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_raw = np.array(list(map(apply_start_end, input_raw)))\n",
        "output_raw = np.array(list(map(apply_start_end, output_raw)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97NOjXUxViTw"
      },
      "source": [
        "#### One vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colgV4twVh56"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=40000, pad_to_max_tokens=False)\n",
        "\n",
        "vectorizer.adapt(np.array(all_raw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XypSmj2RWRoi",
        "outputId": "81c4e188-a46c-4315-a535-bded0fdd1294"
      },
      "source": [
        "vocab = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(vocab, range(len(vocab))))\n",
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IStyZYv3nBMF"
      },
      "source": [
        "# load glove\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDfBaYkrWc_K",
        "outputId": "34085ddb-f49b-4f44-a7fa-f50e9bdfbb00"
      },
      "source": [
        "path_to_glove_file = 'glove.6B.100d.txt'\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "glove_embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        glove_embeddings_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(glove_embeddings_index)} word vectors.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oRipctLWgvD",
        "outputId": "49d31e9b-c290-4f15-de8d-65397cc144d4"
      },
      "source": [
        "num_tokens = len(vocab) + 2\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = glove_embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    # Words not found in embedding index will be all-zeros.\n",
        "    # This includes the representation for \"padding\" and \"OOV\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    hits += 1\n",
        "  else:\n",
        "    misses += 1\n",
        "print(f'Converted {hits} words ({misses} misses)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 23854 words (16146 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfN-KH40WiEn",
        "outputId": "acc217df-d957-452b-96fc-32c2ef30da28"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "vec_X = vectorizer(np.array([[text] for text in input_raw])).numpy()\n",
        "vec_Y = vectorizer(np.array([[text] for text in output_raw])).numpy()\n",
        "X = pad_sequences(vec_X, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "Y = pad_sequences(vec_Y, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = dataset_split(X, Y, valid_split=0.2, test_split=0.1)\n",
        "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 525), (35000, 30), (10000, 525), (10000, 30), (5000, 525), (5000, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm3kg6byYBhM",
        "outputId": "4b9d1d2a-9b16-4806-ad34-d6585b7a411c"
      },
      "source": [
        "x_vocab = len(vocab) + 2\n",
        "y_vocab = len(vocab) + 2\n",
        "x_vocab, y_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40002, 40002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jplXrmW-VdIW"
      },
      "source": [
        "#### Two separate vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr_u50DuNHMM"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "input_vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=encoder_maxlen)\n",
        "output_vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=decoder_maxlen)\n",
        "\n",
        "input_vectorizer.adapt(np.array(input_raw))\n",
        "output_vectorizer.adapt(np.array(output_raw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxhUh6gKOGCW",
        "outputId": "97186e02-828b-4a98-f861-4cfb95a5370e"
      },
      "source": [
        "input_vectorizer.get_vocabulary()[:20], output_vectorizer.get_vocabulary()[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['', '[UNK]', 'the', 'i', 'and'], ['', '[UNK]', 'great', 'the', 'good'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xk18zD_OzfP",
        "outputId": "dc65e520-8424-4c01-a0bc-d2cf65fcda7a"
      },
      "source": [
        "input_vocab = input_vectorizer.get_vocabulary()\n",
        "output_vocab = output_vectorizer.get_vocabulary()\n",
        "\n",
        "input_word_index = dict(zip(input_vocab, range(len(input_vocab))))\n",
        "output_word_index = dict(zip(output_vocab, range(len(output_vocab))))\n",
        "\n",
        "len(input_vocab), len(output_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 12117)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBa5zpBSPTEg",
        "outputId": "4b014882-962e-4118-9c77-5dc04f90c74f"
      },
      "source": [
        "# load glove\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 12:09:44--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-11-27 12:09:44--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-11-27 12:09:44--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.05MB/s    in 6m 27s  \n",
            "\n",
            "2020-11-27 12:16:11 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f866BwX3PVen",
        "outputId": "117021c4-f066-4b34-a5b7-4378f0f202f2"
      },
      "source": [
        "path_to_glove_file = 'glove.6B.100d.txt'\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "glove_embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        glove_embeddings_index[word] = coefs\n",
        "\n",
        "print(f'Found {len(glove_embeddings_index)} word vectors.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS3gOZ2eQmNG"
      },
      "source": [
        "def create_embedding_matrix(vocab, word_index):\n",
        "  num_tokens = len(vocab) + 2\n",
        "  hits = 0\n",
        "  misses = 0\n",
        "\n",
        "  # Prepare embedding matrix\n",
        "  embedding_matrix = np.zeros((num_tokens, EMBEDDING_DIM))\n",
        "  for word, i in word_index.items():\n",
        "    embedding_vector = glove_embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # Words not found in embedding index will be all-zeros.\n",
        "      # This includes the representation for \"padding\" and \"OOV\"\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "      hits += 1\n",
        "    else:\n",
        "      misses += 1\n",
        "  print(f'Converted {hits} words ({misses} misses)')\n",
        "  return embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HByG-rUzSWtl",
        "outputId": "49125f01-5bc1-4963-e514-807766d7719e"
      },
      "source": [
        "input_embedding_matrix = create_embedding_matrix(input_vocab, input_word_index)\n",
        "output_embedding_matrix = create_embedding_matrix(output_vocab, output_word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 15899 words (4101 misses)\n",
            "Converted 8958 words (3159 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBm-yt3cQuKL"
      },
      "source": [
        "X = input_vectorizer(np.array([[text] for text in input_raw])).numpy()\n",
        "Y = output_vectorizer(np.array([[text] for text in output_raw])).numpy()\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = dataset_split(X, Y, valid_split=0.2, test_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc1uQctLUHjH",
        "outputId": "3c19366d-fa8f-48e8-f09d-b027c75d77aa"
      },
      "source": [
        "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 525), (35000, 30), (10000, 525), (10000, 30), (5000, 525), (5000, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsJvM3ZsYrkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bd87f5-a5f8-4a06-9109-c8f525275c16"
      },
      "source": [
        "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 525), (35000, 30), (10000, 525), (10000, 30), (5000, 525), (5000, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AjkbDf1aHlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c272c43d-6cbc-4624-dd89-36a3824baf6c"
      },
      "source": [
        "X_train.shape[0] + X_valid.shape[0] + X_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG_fxdvLLibO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad90507-3213-461b-b7ec-68c53b9afc2f"
      },
      "source": [
        "x_vocab = len(input_vocab) + 2\n",
        "y_vocab = len(output_vocab) + 2\n",
        "x_vocab, y_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20002, 12119)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cS5f1AgVINV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j0x8lrptYhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661a3ef4-fdbc-4b1c-f089-f271ea95bdfc"
      },
      "source": [
        "x_vocab = len(tokenizers[0].word_index)\n",
        "y_vocab = len(tokenizers[1].word_index)\n",
        "x_vocab, y_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43036, 11213)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GspMEDS-qs57"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiNQeGg3tbVN"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, Attention, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.activations import softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RiyLPpasNOZ"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xxRw3crc-3"
      },
      "source": [
        "embedding_dim = 100 #50\n",
        "hidden_dim = 250 #60\n",
        "\n",
        "ENC_LSTM_NUM = 3 #3\n",
        "ENC_LSTM_DROPOUT = 0.4 #0.4\n",
        "ENC_LSTM_RECURRENT_DROPOUT = 0.4 #0.4\n",
        "\n",
        "# Architecture\n",
        "\n",
        "# Encoder\n",
        "enc_emb = Embedding(x_vocab,\n",
        "                    embedding_dim,\n",
        "                    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                    trainable=False)\n",
        "enc_lstms = []\n",
        "for i in range(ENC_LSTM_NUM):\n",
        "  enc_lstms.append(LSTM(hidden_dim, return_sequences=True, return_state=True))\n",
        "dropout = Dropout(ENC_LSTM_DROPOUT)\n",
        "\n",
        "# Decoder\n",
        "dec_emb = Embedding(y_vocab,\n",
        "                    embedding_dim,\n",
        "                    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                    trainable=False)\n",
        "dec_lstm = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
        "attn = Attention()\n",
        "concat = Concatenate()\n",
        "dec_fc = Dense(y_vocab, activation='softmax')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCRT-PAHsShB"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cbN9TsFtxin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715a71cd-2140-409a-9569-69c70d36983e"
      },
      "source": [
        "# Building the model\n",
        "\n",
        "# Encoder\n",
        "encoder_input = Input(shape=(encoder_maxlen,))\n",
        "enc_emb_out = enc_emb(encoder_input)\n",
        "lstm_in = enc_emb_out\n",
        "for i in range(ENC_LSTM_NUM - 1):\n",
        "  lstm_out, h, c = enc_lstms[i](lstm_in)\n",
        "  lstm_out = dropout(lstm_out)\n",
        "  lstm_in = lstm_out\n",
        "enc_output, enc_state_h, enc_state_c = enc_lstms[-1](lstm_in)\n",
        " \n",
        "# Decoder\n",
        "decoder_input = Input(shape=(None,))\n",
        "dec_emb_out = dec_emb(decoder_input)\n",
        "dec_output, dec_state_h, dec_state_c = dec_lstm(dec_emb_out, initial_state=[enc_state_h, enc_state_c])\n",
        "\n",
        "attn_out = attn([dec_output, enc_output])\n",
        "concat_out = concat([dec_output, attn_out])\n",
        "output = dec_fc(concat_out)\n",
        "\n",
        "model = Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_25\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 525)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 525, 100)     4000200     input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  [(None, 525, 250), ( 351000      embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 525, 250)     0           lstm_16[0][0]                    \n",
            "                                                                 lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  [(None, 525, 250), ( 501000      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, None, 100)    4000200     input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_18 (LSTM)                  [(None, 525, 250), ( 501000      dropout_4[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_19 (LSTM)                  [(None, None, 250),  351000      embedding_9[0][0]                \n",
            "                                                                 lstm_18[0][1]                    \n",
            "                                                                 lstm_18[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_4 (Attention)         (None, None, 250)    0           lstm_19[0][0]                    \n",
            "                                                                 lstm_18[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, None, 500)    0           lstm_19[0][0]                    \n",
            "                                                                 attention_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, None, 40002)  20041002    concatenate_4[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 29,745,402\n",
            "Trainable params: 21,745,002\n",
            "Non-trainable params: 8,000,400\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhAQD6ctsE_C"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44gkWMnsXlA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GdBagPjoCA6"
      },
      "source": [
        "def get_model_input(X, Y):\n",
        "  \"\"\"\n",
        "    List of X and Y where Ys last word is excluded\n",
        "  \"\"\"\n",
        "  return [X, Y[:,:-1]]\n",
        "\n",
        "def get_model_output(Y):\n",
        "  \"\"\"\n",
        "    Y input shifted right (first word excluded) and made it third dimensional\n",
        "  \"\"\"\n",
        "  return Y.reshape(Y.shape[0],Y.shape[1], 1)[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlxBwsdmw4CT"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "SAVED_MODEL_PATH = 'model.hdf5'\n",
        "PATIENCE = 3\n",
        "\n",
        "earlystopping = EarlyStopping(patience=PATIENCE, monitor='val_loss', mode='min', verbose=1)\n",
        "checkpointer = ModelCheckpoint(filepath=SAVED_MODEL_PATH, save_best_only=True, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBjqAZ8Ik0o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4fc977-fe7e-4f19-e635-57fc5aa62ce6"
      },
      "source": [
        "history = model.fit(\n",
        "    get_model_input(X_train, Y_train),\n",
        "    get_model_output(Y_train),\n",
        "    epochs=20,\n",
        "    batch_size=32, #32,\n",
        "    validation_data=(\n",
        "        get_model_input(X_valid, Y_valid),\n",
        "        get_model_output(Y_valid)\n",
        "        ),\n",
        "    callbacks=[checkpointer, earlystopping]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1094/1094 [==============================] - 249s 227ms/step - loss: 1.0298 - val_loss: 0.9739\n",
            "Epoch 2/20\n",
            "1094/1094 [==============================] - 249s 228ms/step - loss: 0.9109 - val_loss: 0.9381\n",
            "Epoch 3/20\n",
            "1094/1094 [==============================] - 249s 228ms/step - loss: 0.8777 - val_loss: 0.9234\n",
            "Epoch 4/20\n",
            "1094/1094 [==============================] - 249s 228ms/step - loss: 0.8561 - val_loss: 0.9113\n",
            "Epoch 5/20\n",
            "1094/1094 [==============================] - 248s 227ms/step - loss: 0.8384 - val_loss: 0.9076\n",
            "Epoch 6/20\n",
            "1094/1094 [==============================] - 249s 227ms/step - loss: 0.8266 - val_loss: 0.9005\n",
            "Epoch 7/20\n",
            "1094/1094 [==============================] - 249s 227ms/step - loss: 0.8118 - val_loss: 0.8951\n",
            "Epoch 8/20\n",
            "1094/1094 [==============================] - 243s 222ms/step - loss: 0.8070 - val_loss: 0.9002\n",
            "Epoch 9/20\n",
            "1094/1094 [==============================] - 243s 223ms/step - loss: 0.7939 - val_loss: 0.8971\n",
            "Epoch 10/20\n",
            "1094/1094 [==============================] - 244s 223ms/step - loss: 0.7854 - val_loss: 0.9223\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HZM04VylypP"
      },
      "source": [
        "#### No start/end tokens\n",
        "\n",
        "Epoch 1/20\n",
        "1094/1094 [==============================] - 212s 193ms/step - loss: 0.7794 - val_loss: 0.7334\n",
        "Epoch 2/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.6813 - val_loss: 0.7034\n",
        "Epoch 3/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.6538 - val_loss: 0.6909\n",
        "Epoch 4/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.6345 - val_loss: 0.6831\n",
        "Epoch 5/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.6211 - val_loss: 0.6762\n",
        "Epoch 6/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.6079 - val_loss: 0.6729\n",
        "Epoch 7/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.5947 - val_loss: 0.6728\n",
        "Epoch 8/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.5855 - val_loss: 0.6722\n",
        "Epoch 9/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.5792 - val_loss: 0.6741\n",
        "Epoch 00009: early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzcY9ExpyeWB"
      },
      "source": [
        "#### Start/end token on outputs\n",
        "\n",
        "Epoch 1/20\n",
        "1094/1094 [==============================] - 211s 193ms/step - loss: 1.0006 - val_loss: 0.9524\n",
        "Epoch 2/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.8935 - val_loss: 0.9232\n",
        "Epoch 3/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.8647 - val_loss: 0.9081\n",
        "Epoch 4/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.8473 - val_loss: 0.9112\n",
        "Epoch 5/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.8302 - val_loss: 0.8922\n",
        "Epoch 6/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.8158 - val_loss: 0.8922\n",
        "Epoch 7/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.8120 - val_loss: 0.8955\n",
        "Epoch 8/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.7940 - val_loss: 0.8864\n",
        "Epoch 9/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.7868 - val_loss: 0.8866\n",
        "Epoch 10/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.7802 - val_loss: 0.8960\n",
        "Epoch 11/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.7737 - val_loss: 0.9004\n",
        "Epoch 00011: early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL6aBYU49ntW"
      },
      "source": [
        "#### Start/end token on everything\n",
        "\n",
        "Epoch 1/20\n",
        "1094/1094 [==============================] - 211s 192ms/step - loss: 1.0010 - val_loss: 0.9541\n",
        "Epoch 2/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.8964 - val_loss: 0.9220\n",
        "Epoch 3/20\n",
        "1094/1094 [==============================] - 209s 191ms/step - loss: 0.8699 - val_loss: 0.9037\n",
        "Epoch 4/20\n",
        "1094/1094 [==============================] - 210s 192ms/step - loss: 0.8387 - val_loss: 0.8923\n",
        "Epoch 5/20\n",
        "1094/1094 [==============================] - 209s 191ms/step - loss: 0.8181 - val_loss: 0.8856\n",
        "Epoch 6/20\n",
        "1094/1094 [==============================] - 209s 191ms/step - loss: 0.8104 - val_loss: 0.8819\n",
        "Epoch 7/20\n",
        "1094/1094 [==============================] - 206s 189ms/step - loss: 0.7953 - val_loss: 0.8827\n",
        "Epoch 8/20\n",
        "1094/1094 [==============================] - 209s 191ms/step - loss: 0.7853 - val_loss: 0.8780\n",
        "Epoch 9/20\n",
        "1094/1094 [==============================] - 206s 189ms/step - loss: 0.7793 - val_loss: 0.8818\n",
        "Epoch 10/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.7731 - val_loss: 0.8866\n",
        "Epoch 11/20\n",
        "1094/1094 [==============================] - 207s 189ms/step - loss: 0.7663 - val_loss: 0.8929\n",
        "Epoch 00011: early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_xoptL8iQql"
      },
      "source": [
        "#### Start/end token everything with only one tokenizer (40000 tokens, sostr/eostr not included in vocab)\n",
        "\n",
        "Epoch 1/20\n",
        "1094/1094 [==============================] - 248s 227ms/step - loss: 1.0282 - val_loss: 0.9718\n",
        "Epoch 2/20\n",
        "1094/1094 [==============================] - 247s 225ms/step - loss: 0.9128 - val_loss: 0.9401\n",
        "Epoch 3/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.8783 - val_loss: 0.9174\n",
        "Epoch 4/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.8551 - val_loss: 0.9112\n",
        "Epoch 5/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.8380 - val_loss: 0.9045\n",
        "Epoch 6/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.8228 - val_loss: 0.8978\n",
        "Epoch 7/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.8104 - val_loss: 0.8960\n",
        "Epoch 8/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.7991 - val_loss: 0.8926\n",
        "Epoch 9/20\n",
        "1094/1094 [==============================] - 248s 226ms/step - loss: 0.7885 - val_loss: 0.8903\n",
        "Epoch 10/20\n",
        "1094/1094 [==============================] - 241s 220ms/step - loss: 0.7800 - val_loss: 0.8923\n",
        "Epoch 11/20\n",
        "1094/1094 [==============================] - 247s 226ms/step - loss: 0.7667 - val_loss: 0.8902\n",
        "Epoch 12/20\n",
        "1094/1094 [==============================] - 241s 220ms/step - loss: 0.7553 - val_loss: 0.8925\n",
        "Epoch 13/20\n",
        "1094/1094 [==============================] - 241s 220ms/step - loss: 0.7455 - val_loss: 0.8922\n",
        "Epoch 14/20\n",
        "1094/1094 [==============================] - 241s 220ms/step - loss: 0.7385 - val_loss: 0.8922\n",
        "Epoch 00014: early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Vs4CQL8-xq"
      },
      "source": [
        "#### Start/end token everything with only one tokenizer (40000 tokens)\n",
        "\n",
        "Epoch 1/20\n",
        "1094/1094 [==============================] - 250s 228ms/step - loss: 1.0322 - val_loss: 0.9750\n",
        "Epoch 2/20\n",
        "1094/1094 [==============================] - 249s 228ms/step - loss: 0.9134 - val_loss: 0.9435\n",
        "Epoch 3/20\n",
        "1094/1094 [==============================] - 249s 228ms/step - loss: 0.8806 - val_loss: 0.9225\n",
        "Epoch 4/20\n",
        "1094/1094 [==============================] - 249s 228ms/step - loss: 0.8614 - val_loss: 0.9173\n",
        "Epoch 5/20\n",
        "1094/1094 [==============================] - 249s 228ms/step - loss: 0.8447 - val_loss: 0.9090\n",
        "Epoch 6/20\n",
        "1094/1094 [==============================] - 249s 228ms/step - loss: 0.8296 - val_loss: 0.9032\n",
        "Epoch 7/20\n",
        "1094/1094 [==============================] - 250s 228ms/step - loss: 0.8185 - val_loss: 0.9009\n",
        "Epoch 8/20\n",
        "1094/1094 [==============================] - 244s 223ms/step - loss: 0.8081 - val_loss: 0.9030\n",
        "Epoch 9/20\n",
        "1094/1094 [==============================] - 243s 223ms/step - loss: 0.8023 - val_loss: 0.9044\n",
        "Epoch 10/20\n",
        "1094/1094 [==============================] - 250s 228ms/step - loss: 0.7940 - val_loss: 0.8989\n",
        "Epoch 11/20\n",
        "1094/1094 [==============================] - 244s 223ms/step - loss: 0.7825 - val_loss: 0.9064\n",
        "Epoch 12/20\n",
        "1094/1094 [==============================] - 244s 223ms/step - loss: 0.7806 - val_loss: 0.9073\n",
        "Epoch 13/20\n",
        "1094/1094 [==============================] - 244s 223ms/step - loss: 0.7735 - val_loss: 0.9058\n",
        "Epoch 00013: early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9UYqEvrdZaW"
      },
      "source": [
        "#### Start/end token everything with only one tokenizer (15000 tokens)\n",
        "\n",
        "Epoch 1/20\n",
        "1094/1094 [==============================] - 181s 166ms/step - loss: 0.9847 - val_loss: 0.9354\n",
        "Epoch 2/20\n",
        "1094/1094 [==============================] - 181s 166ms/step - loss: 0.8793 - val_loss: 0.9061\n",
        "Epoch 3/20\n",
        "1094/1094 [==============================] - 181s 166ms/step - loss: 0.8514 - val_loss: 0.8883\n",
        "Epoch 4/20\n",
        "1094/1094 [==============================] - 181s 166ms/step - loss: 0.8289 - val_loss: 0.8793\n",
        "Epoch 5/20\n",
        "1094/1094 [==============================] - 182s 166ms/step - loss: 0.8135 - val_loss: 0.8744\n",
        "Epoch 6/20\n",
        "1094/1094 [==============================] - 181s 166ms/step - loss: 0.7963 - val_loss: 0.8651\n",
        "Epoch 7/20\n",
        "1094/1094 [==============================] - 179s 163ms/step - loss: 0.7806 - val_loss: 0.8732\n",
        "Epoch 8/20\n",
        "1094/1094 [==============================] - 182s 166ms/step - loss: 0.7723 - val_loss: 0.8638\n",
        "Epoch 9/20\n",
        "1094/1094 [==============================] - 181s 166ms/step - loss: 0.7632 - val_loss: 0.8636\n",
        "Epoch 10/20\n",
        "1094/1094 [==============================] - 179s 164ms/step - loss: 0.7527 - val_loss: 0.8664\n",
        "Epoch 11/20\n",
        "1094/1094 [==============================] - 179s 164ms/step - loss: 0.7440 - val_loss: 0.8643\n",
        "Epoch 12/20\n",
        "1094/1094 [==============================] - 179s 163ms/step - loss: 0.7365 - val_loss: 0.8687\n",
        "Epoch 00012: early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa-isMFdrAwn"
      },
      "source": [
        "!\\cp model.hdf5 drive/MyDrive/Colab\\ Notebooks/Deep\\ learning/model.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6i9tJDZsWkz"
      },
      "source": [
        "!\\cp drive/MyDrive/Colab\\ Notebooks/Deep\\ learning/one_vectorizer_model.hdf5 one_vectorizer_model.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHB82c46OEk0"
      },
      "source": [
        "model.load_weights('one_vectorizer_model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTjzGEI0fNjV"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(histories):\n",
        "  \"\"\"\n",
        "  Function for plotting the loss of models that we run.\n",
        "  So its not only visible from tensorboard.\n",
        "  \"\"\"\n",
        "  \n",
        "  loss, val_loss = [], []\n",
        "  for history in histories:\n",
        "    loss += history.history['loss']\n",
        "    val_loss += history.history['val_loss']\n",
        "\n",
        "  epochs = [x+1 for x in range(len(loss))]\n",
        "\n",
        "  loss_data = pd.DataFrame({'epoch':epochs, 'train_loss':loss, 'valid_loss':val_loss})\n",
        "  sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(loss_data, ['epoch']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhkh1S7ffPEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "caa37e35-a361-451a-ecb1-17aaa1241ecf"
      },
      "source": [
        "plot_metrics([history])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9jg-sYVqoS3"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRtsDYqIyH3Z"
      },
      "source": [
        "# Encode\n",
        "encoder_model = Model(encoder_input, [enc_output, enc_state_h, enc_state_c])\n",
        "\n",
        "# Inputs for decode\n",
        "dec_state_input_h = Input(shape=(hidden_dim,))\n",
        "dec_state_input_c = Input(shape=(hidden_dim,))\n",
        "dec_hidden_state_input = Input(shape=(encoder_maxlen, hidden_dim))\n",
        "\n",
        "# Decode\n",
        "dec_emb_out2 = dec_emb(decoder_input)\n",
        "dec_output2, dec_state_h2, dec_state_c2 = dec_lstm(dec_emb_out2, initial_state=[dec_state_input_h, dec_state_input_c])\n",
        "attn_out2 = attn([dec_output2, dec_hidden_state_input])\n",
        "concat_out2 = concat([dec_output2, attn_out2])\n",
        "output = dec_fc(concat_out2)\n",
        "\n",
        "decoder_model = Model([decoder_input] + [dec_hidden_state_input, dec_state_input_h, dec_state_input_c], [output] + [dec_state_h2, dec_state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f7LD2lPgoqD"
      },
      "source": [
        "input_index_word = dict(zip(range(len(input_vocab)), input_vocab))\n",
        "output_index_word = dict(zip(range(len(output_vocab)), output_vocab))\n",
        "\n",
        "reverse_target_word_index=output_index_word\n",
        "reverse_source_word_index=input_index_word\n",
        "target_word_index=output_word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niKRgub0hr-p"
      },
      "source": [
        "index_word = dict(zip(range(len(vocab)), vocab))\n",
        "\n",
        "reverse_target_word_index=index_word\n",
        "reverse_source_word_index=index_word\n",
        "target_word_index=word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcjYXDL75LvC"
      },
      "source": [
        "reverse_target_word_index=tokenizers[1].index_word\n",
        "reverse_source_word_index=tokenizers[0].index_word\n",
        "target_word_index=tokenizers[1].word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CqtUoHy32RK"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  target_seq[0, 0] = target_word_index[start_token]\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "    # sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    try:\n",
        "      sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    except:\n",
        "      sampled_token = '[UNK]'\n",
        "\n",
        "    if(sampled_token != end_token):\n",
        "      decoded_sentence += ' '+sampled_token\n",
        "\n",
        "    # Exit condition: either hit max length or find stop word.\n",
        "    if (sampled_token == end_token  or len(decoded_sentence.split()) >= (decoder_maxlen - 1)):\n",
        "      stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lAJgH68itY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def decode_sequence2(input_seq, length):\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  target_seq[0, 0] = input_seq[0][0]\n",
        "\n",
        "  decoded_sentence = reverse_source_word_index[input_seq[0][0]]\n",
        "  print('first: ', decoded_sentence)\n",
        "  for _ in range(length):\n",
        "\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "    # sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :][1:]) + 1\n",
        "    try:\n",
        "      sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    except:\n",
        "      sampled_token = '[UNK]'\n",
        "\n",
        "    decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnRSImsUnHoX"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def decode_sequence3(input_seq):\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  target_seq[0, 0] = target_word_index['[UNK]']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "    # sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    try:\n",
        "      sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    except:\n",
        "      sampled_token = '[UNK]'\n",
        "\n",
        "    if(sampled_token != '[UNK]'):\n",
        "      decoded_sentence += ' '+sampled_token\n",
        "\n",
        "    # Exit condition: either hit max length or find stop word.\n",
        "    if (sampled_token == '[UNK]'  or len(decoded_sentence.split()) >= (decoder_maxlen - 1)):\n",
        "      stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WXzdaDm9R1R"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for item in input_seq:\n",
        "        if(item != 0 and item != target_word_index[start_token] and item != target_word_index[end_token]):\n",
        "          try:\n",
        "            new_str = reverse_target_word_index[item]\n",
        "          except:\n",
        "            new_str = '[UNK]'\n",
        "          newString = newString + new_str + ' '\n",
        "    return newString\n",
        "\n",
        "def seq2summary2(input_seq):\n",
        "    newString=''\n",
        "    for item in input_seq:\n",
        "        if(item != 0):\n",
        "          try:\n",
        "            new_str = reverse_target_word_index[item]\n",
        "          except:\n",
        "            new_str = '[UNK]'\n",
        "          newString = newString + new_str + ' '\n",
        "    return newString\n",
        "\n",
        "def seq2summary3(input_seq):\n",
        "    newString=''\n",
        "    for item in input_seq:\n",
        "        if(item != 0):\n",
        "          try:\n",
        "            new_str = reverse_target_word_index[item]\n",
        "          except:\n",
        "            new_str = '[UNK]'\n",
        "          newString = newString + new_str + ' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for item in input_seq:\n",
        "      if(item != 0):\n",
        "        try:\n",
        "          new_str = reverse_source_word_index[item]\n",
        "        except:\n",
        "          new_str = '[UNK]'\n",
        "        newString = newString + new_str + ' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qiiy3PgyMjKA"
      },
      "source": [
        "#### No start/end tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gks2rIBct9Qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf4cba2-79f9-465e-ad6e-3b5ad71da9a2"
      },
      "source": [
        "for i in range(5):\n",
        "    print(\"Text:\",seq2text(X_train[i]))\n",
        "    print(\"Original title:\",seq2summary2(Y_train[i]))\n",
        "    print(\"Predicted title:\",decode_sequence2(X_train[i].reshape(1, -1), len([x for x in Y_train[i] if x != 0])))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most \n",
            "Original title: good quality dog food \n",
            "first:  i\n",
            "Predicted title: i best dog food for\n",
            "\n",
            "\n",
            "Text: product arrived labeled as jumbo salted [UNK] peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo \n",
            "Original title: not as advertised \n",
            "first:  product\n",
            "Predicted title: product the best but\n",
            "\n",
            "\n",
            "Text: this is a confection that has been around a few centuries it is a light [UNK] citrus gelatin with nuts in this case [UNK] and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of cs [UNK] the lion the witch and the wardrobe this is the treat that [UNK] [UNK] into selling out his brother and sisters to the witch \n",
            "Original title: delight says it all \n",
            "first:  this\n",
            "Predicted title: this favorite flavor of the\n",
            "\n",
            "\n",
            "Text: if you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal \n",
            "Original title: cough medicine \n",
            "first:  if\n",
            "Predicted title: if a good\n",
            "\n",
            "\n",
            "Text: great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal \n",
            "Original title: great taffy \n",
            "first:  great\n",
            "Predicted title: great love it\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gei912S8dwdz"
      },
      "source": [
        "#### Start/end token everything with only one tokenizer (40000 tokens, sostr/eostr not included in vocab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eIj3AXi46sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6c74bc-aff2-41d6-b16c-f90f2926f6c3"
      },
      "source": [
        "for i in range(10):\n",
        "    i = i\n",
        "    print(\"Text:\",seq2text(X_train[i]))\n",
        "    print(\"Original title:\",seq2summary3(Y_train[i]))\n",
        "    print(\"Predicted title:\",decode_sequence3(X_train[i].reshape(1, -1)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: [UNK] i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most [UNK] \n",
            "Original title: [UNK] good quality dog food [UNK] \n",
            "Predicted title:  great for dogs\n",
            "\n",
            "\n",
            "Text: [UNK] product arrived labeled as jumbo salted peanutsthe peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo [UNK] \n",
            "Original title: [UNK] not as advertised [UNK] \n",
            "Predicted title:  not what i expected\n",
            "\n",
            "\n",
            "Text: [UNK] this is a confection that has been around a few centuries it is a light pillowy citrus gelatin with nuts in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of cs [UNK] the lion the witch and the wardrobe this is the treat that seduces edmund into selling out his brother and sisters to the witch [UNK] \n",
            "Original title: [UNK] delight says it all [UNK] \n",
            "Predicted title:  great for your little\n",
            "\n",
            "\n",
            "Text: [UNK] if you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal [UNK] \n",
            "Original title: [UNK] cough medicine [UNK] \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: [UNK] great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal [UNK] \n",
            "Original title: [UNK] great taffy [UNK] \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: [UNK] i got a wild hair for taffy and ordered this five pound bag the taffy was all very enjoyable with many flavors watermelon root beer melon peppermint grape etc my only complaint is there was a bit too much [UNK] licoriceflavored pieces just not my particular favorites between me my kids and my husband this lasted only two weeks i would recommend this brand of taffy it was a delightful treat [UNK] \n",
            "Original title: [UNK] nice taffy [UNK] \n",
            "Predicted title:  great for those who are the best\n",
            "\n",
            "\n",
            "Text: [UNK] this saltwater taffy had great flavors and was very soft and chewy each candy was individually wrapped well none of the candies were stuck together which did happen in the expensive version [UNK] would highly recommend this candy i served it at a [UNK] party and everyone loved it [UNK] \n",
            "Original title: [UNK] great just as good as the expensive brands [UNK] \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: [UNK] this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying [UNK] \n",
            "Original title: [UNK] wonderful tasty taffy [UNK] \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: [UNK] right now im mostly just sprouting this so my cats can eat the grass they love it i rotate it around with wheatgrass and rye too [UNK] \n",
            "Original title: [UNK] yay barley [UNK] \n",
            "Predicted title:  great for cats\n",
            "\n",
            "\n",
            "Text: [UNK] this is a very healthy dog food good for their digestion also good for small puppies my dog eats her required amount at every feeding [UNK] \n",
            "Original title: [UNK] healthy dog food [UNK] \n",
            "Predicted title:  great for dogs\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6a7biMsdmgo"
      },
      "source": [
        "#### Start/end token everything with only one tokenizer (15000 tokens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgaYSF8Xl4dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cac6fa5-2b99-4a8c-af08-c94599059ab0"
      },
      "source": [
        "for i in range(10):\n",
        "    i = i\n",
        "    print(\"Text:\",seq2summary(X_train[i]))\n",
        "    print(\"Original title:\",seq2summary(Y_train[i]))\n",
        "    print(\"Predicted title:\",decode_sequence(X_train[i].reshape(1, -1)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most \n",
            "Original title: good quality dog food \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: product arrived labeled as jumbo salted [UNK] peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo \n",
            "Original title: not as advertised \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: this is a confection that has been around a few centuries it is a light [UNK] citrus gelatin with nuts in this case [UNK] and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of cs [UNK] the lion the witch and the wardrobe this is the treat that [UNK] [UNK] into selling out his brother and sisters to the witch \n",
            "Original title: delight says it all \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: if you are looking for the secret ingredient in [UNK] i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal \n",
            "Original title: cough medicine \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal \n",
            "Original title: great taffy \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: i got a wild hair for taffy and ordered this five pound bag the taffy was all very enjoyable with many flavors watermelon root beer melon peppermint grape etc my only complaint is there was a bit too much [UNK] [UNK] pieces just not my particular favorites between me my kids and my husband this lasted only two weeks i would recommend this brand of taffy it was a delightful treat \n",
            "Original title: nice taffy \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: this [UNK] taffy had great flavors and was very soft and chewy each candy was individually wrapped well none of the candies were stuck together which did happen in the expensive version [UNK] would highly recommend this candy i served it at a [UNK] party and everyone loved it \n",
            "Original title: great just as good as the expensive brands \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying \n",
            "Original title: wonderful tasty taffy \n",
            "Predicted title:  great taste and good for you\n",
            "\n",
            "\n",
            "Text: right now im mostly just sprouting this so my cats can eat the grass they love it i rotate it around with wheatgrass and rye too \n",
            "Original title: yay barley \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: this is a very healthy dog food good for their digestion also good for small puppies my dog eats her required amount at every feeding \n",
            "Original title: healthy dog food \n",
            "Predicted title:  great product\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}