{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_text_summarizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrick-nanys/text-summarization/blob/main/simple_text_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLvBco2J-xK"
      },
      "source": [
        "## Deep learning homework - Milestone 2\n",
        "#####Topic: NLP - text summarization\n",
        "#####Authors: Patrick Nanys, Mate Jakab (Goal Diggers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGZDgfz_a6HG"
      },
      "source": [
        "###1. Data load from xlsx \n",
        "\n",
        "> Source: https://www.kaggle.com/shashichander009/inshorts-news-data\n",
        "> Source2.0: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAEriAFohCba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc26afa3-acea-444a-c710-9d94153ed058"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#xls = pd.read_excel(\"Inshorts Cleaned Data.xlsx\")\n",
        "xls = pd.read_excel(\"reviews.xlsx\")\n",
        "# Load articles, stories\n",
        "input_raw = xls['Short']\n",
        "# Load headlines for articles and stories\n",
        "output_raw = xls['Headline']\n",
        "\n",
        "# Show example\n",
        "print(input_raw.head(), output_raw.head())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    I have bought several of the Vitality canned d...\n",
            "1    Product arrived labeled as Jumbo Salted Peanut...\n",
            "2    This is a confection that has been around a fe...\n",
            "3    If you are looking for the secret ingredient i...\n",
            "4    Great taffy at a great price.  There was a wid...\n",
            "Name: Short, dtype: object 0    Good Quality Dog Food\n",
            "1        Not as Advertised\n",
            "2    \"Delight\" says it all\n",
            "3           Cough Medicine\n",
            "4              Great taffy\n",
            "Name: Headline, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0CyGJ3cgoT0"
      },
      "source": [
        "###2. Taking out stopwords and shorten words (optional)\n",
        "> Shortening options: lemmatizing/stemmimg\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCwWTYGhymGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39550b0a-746e-4d9a-9819-365477cc644c"
      },
      "source": [
        "# nltk library and used modules\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.corpus import wordnet\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Lemmatize with POS Tag (a given word gets the right POS tag)\n",
        "def get_wordnet_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXMYhpsWncrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756ab2f6-e3a2-4a06-9f19-bc71651075cf"
      },
      "source": [
        "print('Lemmatizing example')\n",
        "\n",
        "words = [\"dogs\", \"are\", \"better\", \"than\", \"cats\"] \n",
        "for w in words:\n",
        "    print(w, \"\\t->\", WordNetLemmatizer().lemmatize(w, get_wordnet_pos(w)))\n",
        "\n",
        "print('\\nStemming example')\n",
        "\n",
        "words = [\"run\", \"ran\", \"runner\", \"running\"] \n",
        "for w in words: \n",
        "    print(w, \"->\", PorterStemmer().stem(w)) "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmatizing example\n",
            "dogs \t-> dog\n",
            "are \t-> be\n",
            "better \t-> well\n",
            "than \t-> than\n",
            "cats \t-> cat\n",
            "\n",
            "Stemming example\n",
            "run -> run\n",
            "ran -> ran\n",
            "runner -> runner\n",
            "running -> run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTMaCpj6iR8J"
      },
      "source": [
        "def takeoutstopwords_and_shorten(data, mode='none'):\n",
        "    data_nltk = []\n",
        "\n",
        "    # nltk's built in lemmatizer, stemmer and detokenizer\n",
        "    lemmatizer = WordNetLemmatizer()  \n",
        "    ps = PorterStemmer()\n",
        "    detok = TreebankWordDetokenizer()\n",
        "\n",
        "    # Cycle through data (range set to 10 instead of data.size until we use this)\n",
        "    for i in tqdm(range(data.size)):  #range(data.size)\n",
        "        # Tokenize\n",
        "        tokenized = word_tokenize(data[i])\n",
        "        # Take out stopwords\n",
        "        without_stopword = [word for word in tokenized if not word in stopwords.words('english')]\n",
        "        # Shorten if parameter 'mode' is 'lemmatize' or 'stem'\n",
        "        shorter = []\n",
        "        for word in without_stopword: \n",
        "            if mode == 'lemmatize':\n",
        "                shorter.append(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n",
        "            elif mode == 'stem':\n",
        "                shorter.append(ps.stem(word))\n",
        "            else:\n",
        "                shorter.append(word)\n",
        "        # Detokenize\n",
        "        back_to_string = detok.detokenize(shorter)\n",
        "\n",
        "        data_nltk.append(back_to_string)\n",
        "\n",
        "    return data_nltk"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtQL4PzhsL3-"
      },
      "source": [
        "# Take out stopwords and shorten input_raw data with lemmatize and stem\n",
        "input_nltk_lemma = takeoutstopwords_and_shorten(input_raw, mode='lemmatize')\n",
        "input_nltk_stem = takeoutstopwords_and_shorten(input_raw, mode='stem')\n",
        "\n",
        "#Maybe it is useless to take out stopwords from output value (it is already short)\n",
        "#output_nltk = takeoutstopwords_and_shorten(output_raw)\n",
        "\n",
        "i = 2\n",
        "print('Example\\n', input_raw[i], '\\n', input_nltk_lemma[i], '\\n', input_nltk_stem[i])\n",
        "\n",
        "#Not connected to tokenization yet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn24taYItgm3"
      },
      "source": [
        "###3. Tokenization and padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5NArR5oguZC"
      },
      "source": [
        "##### Obtaining length data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVFDLC_pg0FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "355eb244-e250-458e-b31c-fcfcd3400cf2"
      },
      "source": [
        "input_lengths = pd.Series([len(x) for x in input_raw])\n",
        "output_lengths = pd.Series([len(str(x)) for x in output_raw])\n",
        "print('Inputs:\\n', input_lengths.describe())\n",
        "print('Outputs:\\n', output_lengths.describe())"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            " count    568454.000000\n",
            "mean        436.225255\n",
            "std         445.349016\n",
            "min          12.000000\n",
            "25%         179.000000\n",
            "50%         302.000000\n",
            "75%         527.000000\n",
            "max       21409.000000\n",
            "dtype: float64\n",
            "Outputs:\n",
            " count    568454.000000\n",
            "mean         23.446018\n",
            "std          14.028805\n",
            "min           1.000000\n",
            "25%          13.000000\n",
            "50%          20.000000\n",
            "75%          30.000000\n",
            "max         128.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvKS-MbphCPK"
      },
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 525\n",
        "decoder_maxlen = 30"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olKeNNn5hLnY"
      },
      "source": [
        "Adding start and stop signs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxQt7HvhhJ76"
      },
      "source": [
        "# should be applied to output\n",
        "def apply_start_end(data):\n",
        "  return data.apply(lambda x: '<start> ' + str(x) + ' <end>')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF4knn3xhpj8"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I72VwUr7hsHG"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def tokenize(inputs, outputs):\n",
        "  # since < and > from default tokens cannot be removed\n",
        "  filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "  oov_token = '<unk>'\n",
        "\n",
        "  input_tokenizer = Tokenizer(oov_token=oov_token)\n",
        "  output_tokenizer = Tokenizer(filters=filters, oov_token=oov_token)\n",
        "\n",
        "  input_tokenizer.fit_on_texts(inputs)\n",
        "  output_tokenizer.fit_on_texts(outputs)\n",
        "\n",
        "  tokenized_inputs = input_tokenizer.texts_to_sequences(inputs)\n",
        "  tokenized_outputs = output_tokenizer.texts_to_sequences(outputs)\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs, (input_tokenizer, output_tokenizer)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJiyIJYciIgT"
      },
      "source": [
        "#### Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3cQXKA3iJx2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def add_padding(inputs, outputs, encoder_maxlen, decoder_maxlen):\n",
        "  padded_inputs = pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "  padded_outputs = pad_sequences(outputs, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
        "  return padded_inputs, padded_outputs"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqLinn2u88J6"
      },
      "source": [
        "###4. Split dataset into train, validation and test datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL15_ImQtNup"
      },
      "source": [
        "def dataset_split(X, Y, valid_split, test_split):\n",
        "  v_start = int(len(X)*(1-valid_split-test_split))\n",
        "  t_start = int(len(X)*(1-test_split))\n",
        "  X_train, Y_train = X[:v_start], Y[:v_start]\n",
        "  X_valid, Y_valid = X[v_start:t_start], Y[v_start:t_start]\n",
        "  X_test , Y_test  = X[t_start:], Y[t_start:]\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "papK44dU9hRk"
      },
      "source": [
        "###5. Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV2oR7no9lTr"
      },
      "source": [
        "# Example data preprocessing\n",
        "\n",
        "# replace unreadable part\n",
        "input_raw = input_raw.replace([\"&#39;\"], [\"'\"], regex=True)\n",
        "output_raw = output_raw.replace([\"&#39;\"], [\"'\"], regex=True)\n",
        "\n",
        "start_end_output = apply_start_end(output_raw[:50000])\n",
        "#lemmatized_inputs = takeoutstopwords_and_shorten(input_raw[:50000], mode='lemmatize')\n",
        "tokenized_inputs, tokenized_outputs, tokenizers = tokenize(input_raw[:50000], start_end_output)\n",
        "X, Y = add_padding(tokenized_inputs, tokenized_outputs, encoder_maxlen, decoder_maxlen)\n",
        "X_train, Y_train, X_valid, Y_valid, X_test, Y_test = dataset_split(X, Y, valid_split=0.2, test_split=0.1)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zsPsF5RwEDA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U18-gdqHQJzA"
      },
      "source": [
        "# Run this cell to skip the above 10 minute preprocessing if you have the file below\n",
        "import pickle\n",
        "\n",
        "PICKLE_FILE = 'preprocess_save.pkl'\n",
        "\n",
        "with open(PICKLE_FILE, 'rb') as file:\n",
        "  loaded_obj = pickle.load(file)\n",
        "\n",
        "(X_train, Y_train, X_valid, Y_valid, X_test, Y_test, tokenizers) = loaded_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsJvM3ZsYrkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7779ce8-ed7a-49af-bcd3-efe47d1371e1"
      },
      "source": [
        "X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape, X_test.shape, Y_test.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 525), (35000, 30), (10000, 525), (10000, 30), (5000, 525), (5000, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AjkbDf1aHlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd0274d-b914-4b3c-b149-8d293e18ed99"
      },
      "source": [
        "X_train.shape[0] + X_valid.shape[0] + X_test.shape[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG_fxdvLLibO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j0x8lrptYhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99b0b99-87d6-45fc-81ae-26b0d075fb9e"
      },
      "source": [
        "x_vocab = len(tokenizers[0].word_index)\n",
        "y_vocab = len(tokenizers[1].word_index)\n",
        "x_vocab, y_vocab"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43036, 11214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GspMEDS-qs57"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiNQeGg3tbVN"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, Attention, Dropout"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RiyLPpasNOZ"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5xxRw3crc-3"
      },
      "source": [
        "embedding_dim = 250 #50\n",
        "hidden_dim = 250 #60\n",
        "\n",
        "ENC_LSTM_NUM = 3 #3\n",
        "ENC_LSTM_DROPOUT = 0.4 #0.4\n",
        "ENC_LSTM_RECURRENT_DROPOUT = 0.4 #0.4\n",
        "\n",
        "# Architecture\n",
        "\n",
        "# Encoder\n",
        "enc_emb = Embedding(x_vocab, embedding_dim)\n",
        "enc_lstms = []\n",
        "for i in range(ENC_LSTM_NUM):\n",
        "  enc_lstms.append(LSTM(hidden_dim, return_sequences=True, return_state=True))\n",
        "dropout = Dropout(ENC_LSTM_DROPOUT)\n",
        "\n",
        "# Decoder\n",
        "dec_emb = Embedding(y_vocab, embedding_dim)\n",
        "dec_lstm = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
        "attn = Attention()\n",
        "concat = Concatenate()\n",
        "dec_fc = Dense(y_vocab, activation='softmax')"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCRT-PAHsShB"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cbN9TsFtxin",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c866f2d2-2c70-4e6b-c090-aa5a08c40808"
      },
      "source": [
        "# Building the model\n",
        "\n",
        "# Encoder\n",
        "encoder_input = Input(shape=(encoder_maxlen,))\n",
        "enc_emb_out = enc_emb(encoder_input)\n",
        "lstm_in = enc_emb_out\n",
        "for i in range(ENC_LSTM_NUM - 1):\n",
        "  lstm_out, h, c = enc_lstms[i](lstm_in)\n",
        "  lstm_out = dropout(lstm_out)\n",
        "  lstm_in = lstm_out\n",
        "enc_output, enc_state_h, enc_state_c = enc_lstms[-1](lstm_in)\n",
        " \n",
        "# Decoder\n",
        "decoder_input = Input(shape=(None,))\n",
        "dec_emb_out = dec_emb(decoder_input)\n",
        "dec_output, dec_state_h, dec_state_c = dec_lstm(dec_emb_out, initial_state=[enc_state_h, enc_state_c])\n",
        "\n",
        "attn_out = attn([dec_output, enc_output])\n",
        "concat_out = concat([dec_output, attn_out])\n",
        "output = dec_fc(concat_out)\n",
        "\n",
        "model = Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_19\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 525)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 525, 250)     10759000    input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_13 (LSTM)                  [(None, 525, 250), ( 501000      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 525, 250)     0           lstm_13[0][0]                    \n",
            "                                                                 lstm_14[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_14 (LSTM)                  [(None, 525, 250), ( 501000      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_17 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, None, 250)    2803500     input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_15 (LSTM)                  [(None, 525, 250), ( 501000      dropout_3[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  [(None, None, 250),  501000      embedding_7[0][0]                \n",
            "                                                                 lstm_15[0][1]                    \n",
            "                                                                 lstm_15[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_3 (Attention)         (None, None, 250)    0           lstm_16[0][0]                    \n",
            "                                                                 lstm_15[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, 500)    0           lstm_16[0][0]                    \n",
            "                                                                 attention_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 11214)  5618214     concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,184,714\n",
            "Trainable params: 21,184,714\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhAQD6ctsE_C"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44gkWMnsXlA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GdBagPjoCA6"
      },
      "source": [
        "def get_model_input(X, Y):\n",
        "  \"\"\"\n",
        "    List of X and Y where Ys last word is excluded\n",
        "  \"\"\"\n",
        "  return [X, Y[:,:-1]]\n",
        "\n",
        "def get_model_output(Y):\n",
        "  \"\"\"\n",
        "    Y input shifted right (first word excluded) and made it third dimensional\n",
        "  \"\"\"\n",
        "  return Y.reshape(Y.shape[0],Y.shape[1], 1)[:,1:]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlxBwsdmw4CT"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBjqAZ8Ik0o2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ceb24c-3465-4ff9-d8d4-e7fcee8a20ad"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "SAVED_MODEL_PATH = 'model.hdf5'\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=SAVED_MODEL_PATH, save_best_only=True, verbose=0)\n",
        "\n",
        "history = model.fit(\n",
        "    get_model_input(X_train, Y_train),\n",
        "    get_model_output(Y_train),\n",
        "    epochs=20,\n",
        "    batch_size=32, #32,\n",
        "    validation_data=(\n",
        "        get_model_input(X_valid, Y_valid),\n",
        "        get_model_output(Y_valid)\n",
        "        ),\n",
        "    callbacks=[checkpointer, earlystopping]\n",
        "    )"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1094/1094 [==============================] - 226s 207ms/step - loss: 1.0032 - val_loss: 0.9543\n",
            "Epoch 2/20\n",
            "1094/1094 [==============================] - 220s 201ms/step - loss: 0.8869 - val_loss: 0.9131\n",
            "Epoch 3/20\n",
            "1094/1094 [==============================] - 219s 200ms/step - loss: 0.8449 - val_loss: 0.8900\n",
            "Epoch 4/20\n",
            "1094/1094 [==============================] - 220s 201ms/step - loss: 0.8166 - val_loss: 0.8822\n",
            "Epoch 5/20\n",
            "1094/1094 [==============================] - 221s 202ms/step - loss: 0.7957 - val_loss: 0.8740\n",
            "Epoch 6/20\n",
            "1094/1094 [==============================] - 220s 201ms/step - loss: 0.7792 - val_loss: 0.8725\n",
            "Epoch 7/20\n",
            "1094/1094 [==============================] - 219s 201ms/step - loss: 0.7646 - val_loss: 0.8699\n",
            "Epoch 8/20\n",
            "1094/1094 [==============================] - 219s 200ms/step - loss: 0.7520 - val_loss: 0.8686\n",
            "Epoch 9/20\n",
            "1094/1094 [==============================] - 218s 199ms/step - loss: 0.7422 - val_loss: 0.8755\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTjzGEI0fNjV"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(histories):\n",
        "  \"\"\"\n",
        "  Function for plotting the loss of models that we run.\n",
        "  So its not only visible from tensorboard.\n",
        "  \"\"\"\n",
        "  \n",
        "  loss, val_loss = [], []\n",
        "  for history in histories:\n",
        "    loss += history.history['loss']\n",
        "    val_loss += history.history['val_loss']\n",
        "\n",
        "  epochs = [x+1 for x in range(len(loss))]\n",
        "\n",
        "  loss_data = pd.DataFrame({'epoch':epochs, 'train_loss':loss, 'valid_loss':val_loss})\n",
        "  sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(loss_data, ['epoch']))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhkh1S7ffPEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5c34bd00-b371-4804-ea6d-a55f65372128"
      },
      "source": [
        "plot_metrics([history])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9jg-sYVqoS3"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRtsDYqIyH3Z"
      },
      "source": [
        "# Encode\n",
        "encoder_model = Model(encoder_input, [enc_output, enc_state_h, enc_state_c])\n",
        "\n",
        "# Inputs for decode\n",
        "dec_state_input_h = Input(shape=(hidden_dim,))\n",
        "dec_state_input_c = Input(shape=(hidden_dim,))\n",
        "dec_hidden_state_input = Input(shape=(encoder_maxlen, hidden_dim))\n",
        "\n",
        "# Decode\n",
        "dec_emb_out2 = dec_emb(decoder_input)\n",
        "dec_output2, dec_state_h2, dec_state_c2 = dec_lstm(dec_emb_out2, initial_state=[dec_state_input_h, dec_state_input_c])\n",
        "attn_out2 = attn([dec_output2, dec_hidden_state_input])\n",
        "concat_out2 = concat([dec_output2, attn_out2])\n",
        "output = dec_fc(concat_out2)\n",
        "\n",
        "decoder_model = Model([decoder_input] + [dec_hidden_state_input, dec_state_input_h, dec_state_input_c], [output] + [dec_state_h2, dec_state_c2])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcjYXDL75LvC"
      },
      "source": [
        "reverse_target_word_index=tokenizers[1].index_word\n",
        "reverse_source_word_index=tokenizers[0].index_word\n",
        "target_word_index=tokenizers[1].word_index"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CqtUoHy32RK"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "  target_seq = np.zeros((1, 1))\n",
        "  target_seq[0, 0] = target_word_index['<start>']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "    # sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    try:\n",
        "      sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    except:\n",
        "      sampled_token = '<unk>'\n",
        "\n",
        "    if(sampled_token!='<end>'):\n",
        "      decoded_sentence += ' '+sampled_token\n",
        "\n",
        "    # Exit condition: either hit max length or find stop word.\n",
        "    if (sampled_token == '<end>'  or len(decoded_sentence.split()) >= (decoder_maxlen - 1)):\n",
        "      stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # Update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WXzdaDm9R1R"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for item in input_seq:\n",
        "        if(item != 0 and item != target_word_index['<start>'] and item != target_word_index['<end>']):\n",
        "          try:\n",
        "            new_str = reverse_target_word_index[item]\n",
        "          except:\n",
        "            new_str = '<unk>'\n",
        "          newString = newString + new_str + ' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for item in input_seq:\n",
        "      if(item != 0):\n",
        "        try:\n",
        "          new_str = reverse_source_word_index[item]\n",
        "        except:\n",
        "          new_str = '<unk>'\n",
        "        newString = newString + new_str + ' '\n",
        "    return newString"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gks2rIBct9Qj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3963675-7a25-43e7-9eda-5ad13ae9939c"
      },
      "source": [
        "for i in range(20):\n",
        "    print(\"Text:\",seq2text(X_train[i]))\n",
        "    print(\"Original title:\",seq2summary(Y_train[i]))\n",
        "    print(\"Predicted title:\",decode_sequence(X_train[i].reshape(1, -1)))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: i have bought several of the vitality canned dog food products and have found them all to be of good quality the product looks more like a stew than a processed meat and it smells better my labrador is finicky and she appreciates this product better than most \n",
            "Original title: good quality dog food \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: product arrived labeled as jumbo salted peanuts the peanuts were actually small sized unsalted not sure if this was an error or if the vendor intended to represent the product as jumbo \n",
            "Original title: not as advertised \n",
            "Predicted title:  not as good as the product\n",
            "\n",
            "\n",
            "Text: this is a confection that has been around a few centuries it is a light pillowy citrus gelatin with nuts in this case filberts and it is cut into tiny squares and then liberally coated with powdered sugar and it is a tiny mouthful of heaven not too chewy and very flavorful i highly recommend this yummy treat if you are familiar with the story of c s lewis' the lion the witch and the wardrobe this is the treat that seduces edmund into selling out his brother and sisters to the witch \n",
            "Original title: delight says it all \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: if you are looking for the secret ingredient in robitussin i believe i have found it i got this in addition to the root beer extract i ordered which was good and made some cherry soda the flavor is very medicinal \n",
            "Original title: cough medicine \n",
            "Predicted title:  good but not as good as the bit own\n",
            "\n",
            "\n",
            "Text: great taffy at a great price there was a wide assortment of yummy taffy delivery was very quick if your a taffy lover this is a deal \n",
            "Original title: great taffy \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: i got a wild hair for taffy and ordered this five pound bag the taffy was all very enjoyable with many flavors watermelon root beer melon peppermint grape etc my only complaint is there was a bit too much red black licorice flavored pieces just not my particular favorites between me my kids and my husband this lasted only two weeks i would recommend this brand of taffy it was a delightful treat \n",
            "Original title: nice taffy \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: this saltwater taffy had great flavors and was very soft and chewy each candy was individually wrapped well none of the candies were stuck together which did happen in the expensive version fralinger's would highly recommend this candy i served it at a beach themed party and everyone loved it \n",
            "Original title: great just as good as the expensive brands \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: this taffy is so good it is very soft and chewy the flavors are amazing i would definitely recommend you buying it very satisfying \n",
            "Original title: wonderful tasty taffy \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: right now i'm mostly just sprouting this so my cats can eat the grass they love it i rotate it around with wheatgrass and rye too \n",
            "Original title: yay barley \n",
            "Predicted title:  my cat loves this\n",
            "\n",
            "\n",
            "Text: this is a very healthy dog food good for their digestion also good for small puppies my dog eats her required amount at every feeding \n",
            "Original title: healthy dog food \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: i don't know if it's the cactus or the tequila or just the unique combination of ingredients but the flavour of this hot sauce makes it one of a kind we picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away when we realized that we simply couldn't find it anywhere in our city we were bummed br br now because of the magic of the internet we have a case of the sauce and are ecstatic because of it br br if you love hot sauce i mean really love hot sauce but don't want a sauce that tastelessly burns your throat grab a bottle of tequila picante gourmet de inclan just realize that once you taste it you will never want to use any other sauce br br thank you for the personal incredible service \n",
            "Original title: the best hot sauce in the world \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: one of my boys needed to lose some weight and the other didn't i put this food on the floor for the chubby guy and the protein rich no by product food up higher where only my skinny boy can jump the higher food sits going stale they both really go for this food and my chubby boy has been losing about an ounce a week \n",
            "Original title: my cats love this diet food better than their regular food \n",
            "Predicted title:  great food\n",
            "\n",
            "\n",
            "Text: my cats have been happily eating felidae platinum for more than two years i just got a new bag and the shape of the food is different they tried the new food when i first put it in their bowls and now the bowls sit full and the kitties will not touch the food i've noticed similar reviews related to formula changes in the past unfortunately i now need to find a new food that my cats will eat \n",
            "Original title: my cats are not fans of the new food \n",
            "Predicted title:  good for cats\n",
            "\n",
            "\n",
            "Text: good flavor these came securely packed they were fresh and delicious i love these twizzlers \n",
            "Original title: fresh and greasy \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: the strawberry twizzlers are my guilty pleasure yummy six pounds will be around for a while with my son and i \n",
            "Original title: strawberry twizzlers yummy \n",
            "Predicted title:  great taste\n",
            "\n",
            "\n",
            "Text: my daughter loves twizzlers and this shipment of six pounds really hit the spot it's exactly what you would expect six packages of strawberry twizzlers \n",
            "Original title: lots of twizzlers just what you expect \n",
            "Predicted title:  great product\n",
            "\n",
            "\n",
            "Text: i love eating them and they are good for watching tv and looking at movies it is not too sweet i like to transfer them to a zip lock baggie so they stay fresh so i can take my time eating them \n",
            "Original title: poor taste \n",
            "Predicted title:  great snack\n",
            "\n",
            "\n",
            "Text: i am very satisfied with my twizzler purchase i shared these with others and we have all enjoyed them i will definitely be ordering more \n",
            "Original title: love it \n",
            "Predicted title:  great\n",
            "\n",
            "\n",
            "Text: twizzlers strawberry my childhood favorite candy made in lancaster pennsylvania by y s candies inc one of the oldest confectionery firms in the united states now a subsidiary of the hershey company the company was established in 1845 as young and smylie they also make apple licorice twists green color and blue raspberry licorice twists i like them all br br i keep it in a dry cool place because is not recommended it to put it in the fridge according to the guinness book of records the longest licorice twist ever made measured 1 200 feet 370 m and weighted 100 pounds 45 kg and was made by y s candies inc this record breaking twist became a guinness world record on july 19 1998 this product is kosher thank you \n",
            "Original title: great sweet candy \n",
            "Predicted title:  great for a little healthy\n",
            "\n",
            "\n",
            "Text: candy was delivered very fast and was purchased at a reasonable price i was home bound and unable to get to a store so this was perfect for me \n",
            "Original title: home delivered twizlers \n",
            "Predicted title:  great\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eIj3AXi46sE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}